{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMjp6XbNjfez"
   },
   "source": [
    "[Link to colab](https://colab.research.google.com/github/lsmin0152/cheb301/blob/main/notebooks/CHEB301_F25_01_intro_pandas.ipynb)\n",
    "# Python basics - files and pandas\n",
    "\n",
    "Now that you have reviewed the basic functionality, let's look at how to *read/write* files, and how to use some of the most common packages (e.g., `pandas`, `matplotlib`, ...).\n",
    "\n",
    "## Reading and writing files\n",
    "\n",
    "Reading and writing files is an important aspect of programming. Let's imagine you have the following list of molecules:\n",
    "\n",
    "```python\n",
    "molecules = ['Amigdalin', 'Fenfuram', 'Estradiol', '2-Methylbutanol']\n",
    "```\n",
    "\n",
    "and you would like to save it in a text file, one name per line.\n",
    "\n",
    "To do so, you could run the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ce7YExUTjfe1"
   },
   "outputs": [],
   "source": [
    "molecules = ['Amigdalin', 'Fenfuram', 'Estradiol', '2-Methylbutanol']\n",
    "\n",
    "with open('./data/molecules.txt', 'w') as file:\n",
    "    file.write('\\n'.join(molecules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vEwQkFtjfe2"
   },
   "source": [
    "Here, `'molecules.txt'` is the name of the file you want to write to. The `'w'` in `'w'` is for writing to the file. If the file does not exist, it will be created. If the file exists, its contents will be overwritten.\n",
    "\n",
    "The `write()` method is used to write to the file. You pass a string to the `write()` method, and it writes that string to the file.\n",
    "\n",
    "The `with` statement is used to make sure that the file is closed properly after you are done writing to it.\n",
    "\n",
    "The string that is written to the file is `'\\n'.join(molecules)`, where `'\\n'` is a line break and the `.join(molecules)` statement joins all the elements in the `molecules` list with `'\\n'`. We can print it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oAc-clIqjfe2"
   },
   "outputs": [],
   "source": [
    "print('\\n'.join(molecules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4AZmDsqjfe3"
   },
   "source": [
    "If we want to read the `molecules.txt` file that we have created and get back the list of molecules. We use a similar synthax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sRA92vJsjfe4"
   },
   "outputs": [],
   "source": [
    "with open('./data/molecules.txt', 'r') as file:\n",
    "    molecules = [molecule for molecule in file.readlines()]\n",
    "print(molecules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKdfm0hZjfe6"
   },
   "source": [
    "Here, `'molecules.txt'` is the name of the file you want to read. The `r` in `r` is for reading the file (as opposed to writing to it).\n",
    "\n",
    "The `open()` function returns a file object that you can use to read the file. The `readlines()` method is used to read the contents of the file, line by line. The lines are returned as a string.\n",
    "\n",
    "However, as you can see,  it still contains the line break character `\\n` at the end of each line.\n",
    "\n",
    "Hence, we apply the `.strip()` method to remove whitespace in front and at the end of the string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xP6erOQ4jfe7"
   },
   "outputs": [],
   "source": [
    "with open('./data/molecules.txt', 'r') as file:\n",
    "    molecules = [molecule.strip() for molecule in file.readlines()]\n",
    "print(molecules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5A7ketkIjfe8"
   },
   "source": [
    "## Pandas\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJGdnvdXjfe9"
   },
   "source": [
    "[Pandas](https://pandas.pydata.org/) is a popular library for data analysis and manipulation in Python. It provides a way to store and manipulate data in a tabular form, similar to a spreadsheet.\n",
    "\n",
    "Here's how to use pandas for reading and writing files:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Reading a CSV file\n",
    "df = pd.read_csv('file.csv')\n",
    "print(df)\n",
    "\n",
    "# Reading an Excel file\n",
    "df = pd.read_excel('file.xlsx')\n",
    "print(df)\n",
    "\n",
    "# Writing a CSV file\n",
    "df.to_csv('file.csv', index=False)\n",
    "\n",
    "# Writing an Excel file\n",
    "df.to_excel('file.xlsx', index=False)\n",
    "```\n",
    "\n",
    "Here, `'file.csv'` and `'file.xlsx'` are the names of the files you want to read or write. You will need to replace them with the actual names of the files you are working with.\n",
    "\n",
    "The `pd.read_csv()` function is used to read a CSV file, and the `pd.read_excel()` function is used to read an Excel file. The functions return a pandas DataFrame (this is what `df` stands for), which is a two-dimensional labeled data structure with columns of potentially different types.\n",
    "\n",
    "The `to_csv()` and `to_excel()` methods are used to write a DataFrame to a CSV file and an Excel file, respectively.\n",
    "\n",
    "The index argument is used to specify whether or not to write the index of the DataFrame to the file. If index is set to False, the index will not be written.\n",
    "\n",
    "Because `pandas` is not a standard Python library, we have to import the module. This the reason for the first line `import pandas as pd`.\n",
    "\n",
    "If you want to go more in-depth, there is also a great [pandas tutorial](https://www.kaggle.com/learn/pandas) on Kaggle Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghVcIJUJjfe9"
   },
   "source": [
    "## ESOL dataset\n",
    "\n",
    "Let's download a dataset containing molecules. We will use the Estimated SOLubility (ESOL) dataset by [Delaney](https://pubs.acs.org/doi/10.1021/ci034243x), as preprocessed by [DeepChem](https://deepchem.io).\n",
    "\n",
    "The Delaney dataset is a collection of small organic molecules with experimental solubility values in water. It is often used as a benchmark dataset for testing and evaluating the performance of machine learning models in predicting the solubility of molecules. The dataset contains 1,084 molecules and a variety of molecular properties, including the solubility value, molecular weight, and atom-level information such as the number of atoms and types of bonds. We will download a `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZKfH9rBjfe9"
   },
   "outputs": [],
   "source": [
    "!wget \"https://raw.githubusercontent.com/lsmin0152/cheb301/refs/heads/main/notebooks/data/delaney-processed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-A0WYFljfe-"
   },
   "source": [
    "The `delaney-processed.csv` file was successfully downloaded.\n",
    "\n",
    "Here, we used the `wget` command with a `!` in front. In Jupyter notebooks, the `!` symbol is used to run `shell`/`terminal` commands directly from the notebook.\n",
    "\n",
    "You can use it to check the version of Python that you're using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q7sO4hu3jfe-"
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4X_OzAAjfe-"
   },
   "source": [
    "This feature is useful when you want to run shell commands directly from the notebook, without having to switch to a terminal or command prompt.\n",
    "\n",
    "It's important to note that the ! symbol only works in Jupyter notebooks, and not in regular Python scripts.\n",
    "\n",
    "### Exercise 01b_01\n",
    "\n",
    "To practice this let's use some more useful shell commands.\n",
    "\n",
    "- `ls` -  lists files in folder\n",
    "- `head file` - show the first lines of the file\n",
    "- `mv file target_location` - move file to target location\n",
    "-  `mkdir folder_name` make a new folder\n",
    "\n",
    "So, your use those commands to:\n",
    "1. See if the `delaney-processed.csv` is in the current folder (`ls`)\n",
    "2. Make a new folder called `data` (`mkdir`)\n",
    "3. Move the `delaney-processed.csv` file to the `data` folder (`mv`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QlYIWuEhjfe-"
   },
   "outputs": [],
   "source": [
    "# write your code here, don't forget the `!` for shell commands\n",
    "\n",
    "\n",
    "\n",
    "# if you want to see the solution, uncomment the following line\n",
    "# %load https://raw.githubusercontent.com/lsmin0152/cheb301/refs/heads/main/notebooks/solutions/solution_01b_01.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vhjnm8-vjfe-"
   },
   "source": [
    "Once you have correctly moved `delaney-processed.csv` to the `data` folder. You should be able to look at the first lines of the file with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zxAN-ne2jfe-"
   },
   "outputs": [],
   "source": [
    "!head data/delaney-processed.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llYlrLvwjfe-"
   },
   "source": [
    "## Handling the ESOL dataset with pandas\n",
    "\n",
    "### Exercise 01b_02\n",
    "\n",
    "You see above that the `.csv` file contains `comma-separated values`. So, let's use pandas to:\n",
    "\n",
    "1. read the file into a DataFrame (use the`read_csv` function and assign it to the `df` variable)\n",
    "2. show the first 5 rows using `df.head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v1hREkfnjfe-"
   },
   "outputs": [],
   "source": [
    "# Let's assume, we have not yet imported pandas\n",
    "# Start by importing the pandas module\n",
    "\n",
    "# Read the ESOL dataset into a DataFrame\n",
    "\n",
    "# Inspect the first 5 rows of the DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-j8AUlNjfe_"
   },
   "outputs": [],
   "source": [
    "# For the solution, uncomment the following line:\n",
    "# %load https://raw.githubusercontent.com/lsmin0152/cheb301/refs/heads/main/notebooks/solutions/solution_01b_02.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IP1GsHpnjfe_"
   },
   "outputs": [],
   "source": [
    "#On Google Colab you can run this command to make the dataframe interactive.\n",
    "%load_ext google.colab.data_table\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBlZLBF2jfe_"
   },
   "source": [
    "### Exercise 01b_03\n",
    "\n",
    "Let's focus on a single colum for the moment.\n",
    "\n",
    "You can access a specific column of the DataFrame by using square bracket notation and the name of the column, such as `df[\"measured log solubility in mols per litre\"]`.\n",
    "\n",
    "You can also perform operations on a specific column of the DataFrame, such as calculating the mean value, by using methods such as `mean()`.\n",
    "\n",
    "Try this in the code cell below, and save the mean solubility in the variable `mean_solubility`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-uvux6cyjfe_"
   },
   "outputs": [],
   "source": [
    "# Access a the \"measured log solubility in mols per litre\" column\n",
    "\n",
    "\n",
    "# Calculate mean statistics on that column\n",
    "\n",
    "\n",
    "# For the solution, uncomment the following line:\n",
    "# %load https://raw.githubusercontent.com/lsmin0152/cheb301/refs/heads/main/notebooks/solutions/solution_01b_03.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vakOcTLjfe_"
   },
   "source": [
    "Once you have this you could the following example:\n",
    "\n",
    "```python\n",
    "# Selecting rows based on conditions\n",
    "high_solubility = df[df[\"measured log solubility in mols per litre\"] > mean_solubility]\n",
    "print(high_solubility)\n",
    "\n",
    "# Adding a new column to the DataFrame\n",
    "df[\"Solubility Class\"] = \"Low\"\n",
    "df.loc[df[\"measured log solubility in mols per litre\"] > mean_solubility, \"Solubility Class\"] = \"High\"\n",
    "print(df.head())\n",
    "\n",
    "# Grouping data by a column\n",
    "grouped = df.groupby(\"Solubility Class\")\n",
    "print(grouped.mean())\n",
    "\n",
    "# Sorting the DataFrame\n",
    "df.sort_values(\"measured log solubility in mols per litre\", ascending=False, inplace=True)\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "In this example, you can see how to select rows based on conditions using boolean indexing, add a new column to the DataFrame, group data by a column, sort the DataFrame, and write the DataFrame to a CSV file.\n",
    "\n",
    "The `df[df[\"measured log solubility in mols per litre\"] > mean_solubility]` line selects rows from the DataFrame where the Solubility column is greater than the mean solubility.\n",
    "\n",
    "The `df[\"Solubility Class\"] = \"Low\"` line adds a new column to the DataFrame, and the `df.loc[df[\"measured log solubility in mols per litre\"] > mean_solubility`, `\"Solubility Class\"] = \"High\"` line sets the values in the new column based on conditions.\n",
    "\n",
    "The `grouped = df.groupby(\"Solubility Class\")` line groups the data by the Solubility Class column, and the `grouped.mean()` line calculates the mean value of each group.\n",
    "\n",
    "The `df.sort_values(\"Solubility\", ascending=False, inplace=True)` line sorts the DataFrame in descending order based on the Solubility column.\n",
    "\n",
    "That's a brief overview of some of the basic operations you can perform on the ESOL dataset using pandas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uph_ik7vjffA"
   },
   "source": [
    "### Additional pandas functionality\n",
    "\n",
    "You can do many more things with pandas as also described in the [documentation](https://pandas.pydata.org/docs/getting_started/intro_tutorials/index.html). Most of the questions that you will have will certainly will already have been answered by someone on [StackOverflow](https://stackoverflow.com/), and you could use tools like [ChatGPT](https://chat.openai.com) as a personal interactive tutor.\n",
    "\n",
    "Here, just some additional examples how you could merge/concatenate DataFrames:\n",
    "\n",
    "```python\n",
    "# Merging DataFrames\n",
    "df1 = df[[\"Compound ID\", \"measured log solubility in mols per litre\"]]\n",
    "df2 = df[[\"Compound ID\", \"SMILES\"]]\n",
    "merged = pd.merge(df1, df2, on=\"Compound ID\")\n",
    "print(merged.head())\n",
    "```\n",
    "\n",
    "```python\n",
    "# Concatenating DataFrames\n",
    "df3 = df[[\"Compound ID\", \"measured log solubility in mols per litre\"]].head(10)\n",
    "df4 = df[[\"Compound ID\", \"SMILES\"]].tail(10)\n",
    "concatenated = pd.concat([df3, df4])\n",
    "print(concatenated)\n",
    "```\n",
    "\n",
    "Or handle missing values in your DataFrame (there are no missing values in the ESOL dataset).\n",
    "\n",
    "```python\n",
    "# Handling missing values\n",
    "df[\"Compound ID\"].fillna(\"\", inplace=True)\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1be16fbddf550357e4e46540ee01bc6d12a48d7bc56fc8427cd30121d5943dc8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
